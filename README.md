# ğŸ“ˆ AI Agent Report Maker - Hackathon Project (2nd Place ğŸ†)

## ğŸ“œ Project Overview

This project focuses on processing and analyzing financial transaction data for insights generation. The primary goals were to develop an intelligent AI agent capable of integrating multiple data sources, cleaning and transforming the data, and applying machine learning models for fraud detection and expense forecasting. The final solution combines these models into a report-generating AI agent to aid financial institutions in decision-making and customer insights.

### ğŸ”‘ Key Objectives

1. **Data Collection and API Integration**: Retrieve client and card data via API, and transaction data from a CSV file.
2. **Data Preprocessing and Transformation**: Clean and merge datasets, engineer features, and handle categorical encoding.
3. **Machine Learning Models**:
   - **Fraud Detection**: A model to classify transactions as fraudulent or non-fraudulent.
   - **Expense Forecasting**: A time-series model to forecast future monthly expenses for clients.
4. **AI Agent for Report Generation**: An agent built using LangChain and a small Llama-based language model to summarize and present insights based on user prompts.

---

## ğŸ“‚ Project Structure

```text
â”œâ”€â”€ data/                      
â”‚   â”œâ”€â”€ raw/                   # Raw data files
â”‚   â””â”€â”€ processed/             # Processed datasets              
â”‚
â”œâ”€â”€ models/                    # Saved models for reuse and testing
â”‚
â”œâ”€â”€ notebooks/                 # Jupyter notebooks with experiments and tests
â”‚   â”œâ”€â”€ 01_task1_presetup.ipynb
â”‚   â”œâ”€â”€ 02_task1.ipynb
â”‚   â”œâ”€â”€ 03_task2.ipynb
â”‚   â”œâ”€â”€ 04_fraud_prepro.ipynb
â”‚   â”œâ”€â”€ 05_fraud_model.ipynb
â”‚   â”œâ”€â”€ 06_forecast_prepro.ipynb
â”‚   â”œâ”€â”€ 07_Forecast_LGBM.ipynb
â”‚   â”œâ”€â”€ 08_Forecast_AutoGluon.ipynb
â”‚   â””â”€â”€ 09_agent_experiments.ipynb
â”‚
â”œâ”€â”€ predictions/               # Predictions output files for evaluation
â”‚   â”œâ”€â”€ predictions_1.json     # Task 1 predictions
â”‚   â”œâ”€â”€ predictions_3.json     # Task 3 fraud detection predictions
â”‚   â””â”€â”€ predictions_4.json     # Task 4 expense forecast predictions
â”‚
â”œâ”€â”€ reports/                   # Generated reports and figures
â”‚   â”œâ”€â”€ figures/               # Plots and figures
â”‚   â””â”€â”€ {summary_report}.pdf   # Final PDF summary report      
â”‚
â”œâ”€â”€ src/                       # Source code
â”‚   â”œâ”€â”€ agent/                 # AI agent scripts
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ agent.py           # AI agent implementation
â”‚   â”‚   â””â”€â”€ tools.py           # Supporting tools for agent functions
â”‚   â”œâ”€â”€ data/                  # Data processing scripts
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ api_calls.py       # API interaction scripts (not implemented due to server limitations)
â”‚   â”‚   â”œâ”€â”€ data_functions.py  # Data processing functions
â”‚   â”‚   â””â”€â”€ data_processing.py # Custom module for fraud detection preprocessing and train-test split
â”‚   â””â”€â”€ models/                # Model scripts and configurations
â”‚
â”œâ”€â”€ tests/                     # Unit tests for verification
â”‚   â”œâ”€â”€ agent_test.py          # Unit tests for the AI agent
â”‚   â”œâ”€â”€ statistics_test.py     # Unit tests for data functions
â”‚   â””â”€â”€ conftest.py            # Pytest configuration                    
â”‚
â”œâ”€â”€ Challenge.md               # Challenge description
â”œâ”€â”€ README.md                  # Project documentation
â”œâ”€â”€ LICENSE                    # License information
â””â”€â”€ requirements.txt           # Project dependencies
```

---

## ğŸ“ Data and API Usage

The following APIs and datasets are used in this project:

- **Client Data API**: Retrieves demographic and account-related client information. *(Note: API calls are not fully implemented due to server limitations.)*
- **Card Data API**: Fetches card-related details such as card type, limit, and activation date for each client.
- **Transaction Data**: Large CSV file containing all transaction records for analysis, efficiently handled using **Polars** library due to its size and the need for optimized processing.

---

## ğŸ§‘â€ğŸ’» Modeling and AI Agent Creation

This project involved extensive data processing, feature engineering, and modeling to build a solution for fraud detection, expense forecasting, and AI-based report generation. Below are the key components of the modeling and agent creation process.

### Fraud Detection Model

- **Data Processing**: The `data_processing.py` module was created to handle data cleaning, feature engineering, and train-test splitting. Downsampling was applied to balance the fraud detection classes.
- **Modeling**: LightGBM (LGBM) was chosen for its efficiency and performance. The model was trained using cross-validation, achieving:
  - **Training Balanced Accuracy**: `[0.999, 0.999, 0.999, 0.999, 1.000]`
  - **Validation Balanced Accuracy**: `[0.947, 0.950, 0.952, 0.943, 0.944]`
  - **Mean Validation Score**: `0.947`

### Expense Forecasting Model

For expense forecasting, transaction data was combined with client demographics to enhance feature richness. Key modeling steps included:

- **Feature Engineering**: Rolling features and lagged values were created using **MLForecast** to capture temporal spending patterns. Static client features like `current_age` and `monthly_income` were also used. More advanced features were explored but not implemented due to time constraints.
- **Hyperparameter Tuning**: Conducted through `LGBM-Forecast_Hyperparameter_tunning.py`, optimizing LightGBM model parameters for improved performance.
- **Alternative Model**: **AutoGluonâ€™s TimeSeriesPredictor** was tested in a separate Conda environment and yielded similar results.
- **Model Results**: Single-fold validation was employed due to inconsistent date availability across clients, with the following metrics:
  - **Validation R2**: `0.772`
  - **Validation RMSE**: `314.361`

### AI Agent for Report Generation

The AI agent, implemented in `agent.py`, leverages LangChain and a locally hosted Llama 3.2:1b model. The agent processes natural language prompts to generate client-specific financial reports, using extracted date ranges to focus the analysis.

**Key Features**:
- **Date Extraction**: Using prompt engineering, the agent extracts start and end dates from text prompts, defaulting to the first and last days of a month if dates are partially specified.
- **Data Processing**: The agent calls functions from `data_functions.py` to generate summaries on earnings, expenses, and cash flow over the specified date range.
- **Report Generation**: The processed data is compiled into a PDF report that includes insights such as financial summaries and graphics, providing actionable information for financial decision-making.

This combination of models and an AI-driven reporting agent allows for dynamic, data-driven insights generation, enhancing the utility of transaction and client data for financial analysis.

---

## ğŸ§ª Testing and Evaluation

- **Unit Tests**: Tests are available in the `tests/` folder. Key tests include:
  - `agent_test.py`: Tests for the AI agent's functionality.
  - `statistics_test.py`: Tests for data processing and query functions.

- **Evaluation Metrics**:
  - **Fraud Detection**: Balanced Accuracy Score.
  - **Expense Forecasting**: R2 Score for prediction accuracy.

Run the tests using the following command:
```bash
python -m pytest tests/test_module.py
```

---

